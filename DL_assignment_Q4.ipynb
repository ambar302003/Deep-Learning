{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8516913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df40544",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e3ef6f9",
   "metadata": {},
   "source": [
    "#Loading and Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4247d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 182040794/182040794 [00:50<00:00, 3587845.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 64275384/64275384 [00:22<00:00, 2866036.09it/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = datasets.SVHN(root='./data', split='train', download=True, transform=transform)\n",
    "test_data = datasets.SVHN(root='./data', split='test', download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "raw",
   "id": "34ac0d64",
   "metadata": {},
   "source": [
    "#Defining LeNet5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123947ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce992e18",
   "metadata": {},
   "source": [
    "#Defining AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64efc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = models.alexnet(pretrained=False).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6754d431",
   "metadata": {},
   "source": [
    "# Loading Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf74f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = {\n",
    "    \"LeNet-5\": LeNet5,\n",
    "    \"AlexNet\": AlexNet,\n",
    "    \"VGG\": models.vgg16,\n",
    "    \"ResNet-18\": models.resnet18,\n",
    "    \"ResNet-50\": models.resnet50,\n",
    "    \"ResNet-101\": models.resnet101\n",
    "}\n",
    "\n",
    "def load_pretrained_weights(model_name):\n",
    "    if model_name == \"LeNet-5\":\n",
    "        return LeNet5().to(device)\n",
    "    elif model_name == \"AlexNet\":\n",
    "        model = AlexNet(num_classes=10)\n",
    "        pretrained_dict = models.alexnet(pretrained=True).state_dict()\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        # Update the state dict\n",
    "        model_dict.update(pretrained_dict)\n",
    "        # Load the updated state dict\n",
    "        model.load_state_dict(model_dict)\n",
    "        return model.to(device)\n",
    "    else:\n",
    "        model = models_list[model_name](pretrained=True)\n",
    "        # Replace the last layer with custom output layer to match SVHN\n",
    "        if \"ResNet\" in model_name:\n",
    "            num_ftrs = model.fc.in_features\n",
    "            model.fc = nn.Linear(num_ftrs, 10)\n",
    "        else:\n",
    "            num_ftrs = model.classifier[-1].in_features\n",
    "            model.classifier[-1] = nn.Linear(num_ftrs, 10)\n",
    "        return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66803de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {100*train_accuracy:.2f}%\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555af180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {100*test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b465704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "for model_name in models_list.keys():\n",
    "    my_list.append(model_name)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1de7679",
   "metadata": {},
   "source": [
    "#LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd0780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet-5...\n",
      "Epoch 1/5, Train Loss: 2.2509, Train Accuracy: 18.92%\n",
      "Epoch 2/5, Train Loss: 2.2355, Train Accuracy: 18.92%\n",
      "Epoch 3/5, Train Loss: 2.2295, Train Accuracy: 18.92%\n",
      "Epoch 4/5, Train Loss: 2.1041, Train Accuracy: 25.04%\n",
      "Epoch 5/5, Train Loss: 1.4657, Train Accuracy: 52.16%\n",
      "Testing LeNet-5...\n",
      "Test Accuracy: 68.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_pretrained_weights(my_list[0])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[0]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[0]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62cbdb08",
   "metadata": {},
   "source": [
    "#VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_weights(my_list[2])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[2]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[2]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b762e319",
   "metadata": {},
   "source": [
    "#AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_weights(my_list[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[1]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[1]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25b7fe07",
   "metadata": {},
   "source": [
    "#Resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_weights(my_list[3])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[3]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[3]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f3b2dc8",
   "metadata": {},
   "source": [
    "#Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79531fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_weights(my_list[4])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[4]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[4]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b05be75a",
   "metadata": {},
   "source": [
    "#Resnet 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pretrained_weights(my_list[5])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(f\"Training {my_list[5]}...\")\n",
    "train_model(model, criterion, optimizer)\n",
    "print(f\"Testing {my_list[5]}...\")\n",
    "test_model(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ff76c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
